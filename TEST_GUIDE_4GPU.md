# ComfyUI å¤š GPU æµ‹è¯•æŒ‡å—ï¼ˆ4 å¡æœåŠ¡å™¨ï¼‰

**æµ‹è¯•æ—¥æœŸ**: 2025-11-05
**ç›®æ ‡**: åœ¨å®é™… 4 å¡æœåŠ¡å™¨ä¸ŠéªŒè¯å¤š GPU æ¶æ„

---

## ğŸ“‹ æµ‹è¯•å‰å‡†å¤‡

### 1. æœåŠ¡å™¨ç¡¬ä»¶è¦æ±‚

```bash
# æ£€æŸ¥ GPU æ•°é‡
nvidia-smi --list-gpus
# åº”è¯¥æ˜¾ç¤º 4 å¼  GPU

# æ£€æŸ¥ GPU è¯¦ç»†ä¿¡æ¯
nvidia-smi

# æ£€æŸ¥å†…å­˜
free -h
# å»ºè®® 64GB+

# æ£€æŸ¥ CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
# åº”è¯¥æ˜¾ç¤º: CUDA: True, GPUs: 4
```

### 2. ç¡®ä¿ ComfyUI å• GPU æ¨¡å¼æ­£å¸¸

```bash
# å…ˆæµ‹è¯•åŸæœ‰å• GPU æ¨¡å¼æ˜¯å¦æ­£å¸¸
export COMFY_MULTI_GPU_SCHED=0
python main.py --listen 0.0.0.0 --port 8188

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•
curl http://localhost:8188
# åº”è¯¥è¿”å› ComfyUI å‰ç«¯é¡µé¢
```

æŒ‰ `Ctrl+C` åœæ­¢ï¼Œç¡®è®¤å• GPU æ¨¡å¼æ²¡é—®é¢˜ã€‚

---

## ğŸš€ é˜¶æ®µ 1: å¯åŠ¨å¤š GPU æ¨¡å¼ï¼ˆä¸ä½¿ç”¨ Nginxï¼‰

### æ­¥éª¤ 1.1: å¯åŠ¨ ComfyUI

```bash
# å¯åŠ¨å¤š GPU æ¨¡å¼
./start_multi_gpu.sh
```

### æ­¥éª¤ 1.2: æ£€æŸ¥å¯åŠ¨æ—¥å¿—

**åº”è¯¥çœ‹åˆ°ä»¥ä¸‹å…³é”®æ—¥å¿—**ï¼š

```
âœ… Multi-GPU scheduling ENABLED
ğŸš€ Multi-GPU mode ENABLED with 4 GPUs
ğŸ“‹ Created 4 task queues for multi-GPU scheduling
ğŸš€ Started worker thread for GPU 0
ğŸš€ Started worker thread for GPU 1
ğŸš€ Started worker thread for GPU 2
ğŸš€ Started worker thread for GPU 3
ğŸ”¥ [GPU 0] Starting warmup...
âœ… [GPU 0] Warmup completed
ğŸ”¥ [GPU 1] Starting warmup...
âœ… [GPU 1] Warmup completed
ğŸ”¥ [GPU 2] Starting warmup...
âœ… [GPU 2] Warmup completed
ğŸ”¥ [GPU 3] Starting warmup...
âœ… [GPU 3] Warmup completed
ğŸ” Checking custom nodes compatibility...
âœ… No obvious device hardcoding detected
```

**âš ï¸ å¦‚æœçœ‹åˆ°é”™è¯¯**ï¼š
- æ£€æŸ¥ GPU æ•°é‡æ˜¯å¦ä¸º 4
- æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
- æŸ¥çœ‹å®Œæ•´é”™è¯¯ä¿¡æ¯

### æ­¥éª¤ 1.3: éªŒè¯åŸºæœ¬åŠŸèƒ½ï¼ˆç›´æ¥è®¿é—®åç«¯ï¼‰

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯

# æµ‹è¯• 1: æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
curl http://localhost:8188
# åº”è¯¥è¿”å›å‰ç«¯é¡µé¢

# æµ‹è¯• 2: æ£€æŸ¥é˜Ÿåˆ—æ±‡æ€»
curl http://localhost:8188/queue/all | jq
# åº”è¯¥è¿”å› 4 ä¸ªé˜Ÿåˆ—çš„çŠ¶æ€
```

**é¢„æœŸè¾“å‡º**ï¼š
```json
{
  "queues": [
    {"gpu_id": 0, "queue_running": [], "queue_pending": [], "running_count": 0, "pending_count": 0},
    {"gpu_id": 1, "queue_running": [], "queue_pending": [], "running_count": 0, "pending_count": 0},
    {"gpu_id": 2, "queue_running": [], "queue_pending": [], "running_count": 0, "pending_count": 0},
    {"gpu_id": 3, "queue_running": [], "queue_pending": [], "running_count": 0, "pending_count": 0}
  ],
  "total_running": 0,
  "total_pending": 0
}
```

---

## ğŸ§ª é˜¶æ®µ 2: æµ‹è¯•ä»»åŠ¡æäº¤ï¼ˆæ‰‹åŠ¨æŒ‡å®š GPUï¼‰

### æ­¥éª¤ 2.1: å‡†å¤‡æµ‹è¯• workflow

åˆ›å»ºç®€å•çš„æµ‹è¯• workflowï¼ˆ`test_workflow.json`ï¼‰ï¼š

```json
{
  "3": {
    "inputs": {
      "seed": 123456,
      "steps": 20,
      "cfg": 8.0,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1.0,
      "model": ["4", 0],
      "positive": ["6", 0],
      "negative": ["7", 0],
      "latent_image": ["5", 0]
    },
    "class_type": "KSampler"
  },
  "4": {
    "inputs": {
      "ckpt_name": "ä½ çš„æ¨¡å‹åç§°.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "5": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "6": {
    "inputs": {
      "text": "beautiful landscape, high quality",
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "7": {
    "inputs": {
      "text": "bad quality, blurry",
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": ["3", 0],
      "vae": ["4", 2]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["8", 0]
    },
    "class_type": "SaveImage"
  }
}
```

**âš ï¸ é‡è¦**: ä¿®æ”¹ `"ckpt_name"` ä¸ºä½ æœåŠ¡å™¨ä¸Šå®é™…å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶åã€‚

### æ­¥éª¤ 2.2: å‘ä¸åŒ GPU æäº¤ä»»åŠ¡

```bash
# æäº¤åˆ° GPU 0ï¼ˆé€šè¿‡ headerï¼‰
curl -X POST http://localhost:8188/prompt \
  -H "Content-Type: application/json" \
  -H "X-TARGET-GPU: 0" \
  -d @test_workflow.json

# æäº¤åˆ° GPU 1
curl -X POST http://localhost:8188/prompt \
  -H "Content-Type: application/json" \
  -H "X-TARGET-GPU: 1" \
  -d @test_workflow.json

# æäº¤åˆ° GPU 2
curl -X POST http://localhost:8188/prompt \
  -H "Content-Type: application/json" \
  -H "X-TARGET-GPU: 2" \
  -d @test_workflow.json

# æäº¤åˆ° GPU 3
curl -X POST http://localhost:8188/prompt \
  -H "Content-Type: application/json" \
  -H "X-TARGET-GPU: 3" \
  -d @test_workflow.json
```

### æ­¥éª¤ 2.3: ç›‘æ§æ‰§è¡Œ

**ç»ˆç«¯ 1 - æŸ¥çœ‹æ—¥å¿—**ï¼š
```bash
tail -f logs/comfyui_*.log
```

**åº”è¯¥çœ‹åˆ°**ï¼š
```
Routing prompt abc123 to GPU 0
ğŸ”§ [GPU 0] Worker started on cuda:0
âœ… [GPU 0] Prompt abc123 executed in 15.32s

Routing prompt def456 to GPU 1
ğŸ”§ [GPU 1] Worker started on cuda:1
âœ… [GPU 1] Prompt def456 executed in 15.18s

...
```

**ç»ˆç«¯ 2 - ç›‘æ§ GPU**ï¼š
```bash
watch -n 1 nvidia-smi
```

**åº”è¯¥çœ‹åˆ°**ï¼š
- 4 å¼  GPU éƒ½æœ‰è´Ÿè½½
- æ¯å¼  GPU çš„ VRAM ä½¿ç”¨é‡ç›¸è¿‘
- è¿›ç¨‹åç§°éƒ½æ˜¯ `python main.py`ï¼ˆåŒä¸€ä¸ªè¿›ç¨‹ï¼‰

**ç»ˆç«¯ 3 - æŸ¥è¯¢é˜Ÿåˆ—çŠ¶æ€**ï¼š
```bash
watch -n 2 "curl -s http://localhost:8188/queue/all | jq '.queues[] | {gpu: .gpu_id, running: .running_count, pending: .pending_count}'"
```

---

## ğŸ¯ é˜¶æ®µ 3: å¹¶å‘å‹åŠ›æµ‹è¯•

### æ­¥éª¤ 3.1: æ‰¹é‡å¹¶å‘æäº¤

```bash
# åˆ›å»ºå¹¶å‘æµ‹è¯•è„šæœ¬
cat > test_concurrent.sh << 'EOF'
#!/bin/bash

echo "ğŸš€ Starting concurrent test..."

# å‘æ¯ä¸ª GPU æäº¤ 10 ä¸ªä»»åŠ¡
for gpu in 0 1 2 3; do
  echo "Submitting 10 tasks to GPU $gpu"
  for i in {1..10}; do
    curl -X POST http://localhost:8188/prompt \
      -H "Content-Type: application/json" \
      -H "X-TARGET-GPU: $gpu" \
      -d @test_workflow.json \
      -s > /dev/null &
  done
done

wait

echo "âœ… All tasks submitted!"
echo "Check queue status:"
curl -s http://localhost:8188/queue/all | jq
EOF

chmod +x test_concurrent.sh
./test_concurrent.sh
```

### æ­¥éª¤ 3.2: ç›‘æ§æŒ‡æ ‡

```bash
# æŸ¥çœ‹æ¯ä¸ª GPU çš„æ€§èƒ½æŒ‡æ ‡
tail -f logs/comfyui_*.log | grep "ğŸ“Š"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸ“Š [GPU 0] tasks=10, success=100.0%, queue=2.5, wait=150ms, exec=15234ms, oom=0
ğŸ“Š [GPU 1] tasks=10, success=100.0%, queue=2.3, wait=142ms, exec=15180ms, oom=0
ğŸ“Š [GPU 2] tasks=10, success=100.0%, queue=2.6, wait=158ms, exec=15298ms, oom=0
ğŸ“Š [GPU 3] tasks=10, success=100.0%, queue=2.4, wait=145ms, exec=15210ms, oom=0
```

### æ­¥éª¤ 3.3: éªŒè¯æ€§èƒ½æå‡

```bash
# åˆ›å»ºæ€§èƒ½å¯¹æ¯”æµ‹è¯•
cat > benchmark.sh << 'EOF'
#!/bin/bash

echo "=== æ€§èƒ½æµ‹è¯• ==="

# æµ‹è¯• 1: å• GPU æ¨¡å¼ï¼ˆ10 ä¸ªä»»åŠ¡ä¸²è¡Œï¼‰
echo "æµ‹è¯• 1: å• GPU æ¨¡å¼"
start=$(date +%s)
for i in {1..10}; do
  curl -X POST http://localhost:8188/prompt \
    -H "Content-Type: application/json" \
    -H "X-TARGET-GPU: 0" \
    -d @test_workflow.json -s > /dev/null
done
end=$(date +%s)
single_time=$((end - start))
echo "å• GPU å®Œæˆ 10 ä¸ªä»»åŠ¡è€—æ—¶: ${single_time}s"

# ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
sleep 5

# æµ‹è¯• 2: 4 GPU å¹¶è¡Œï¼ˆ40 ä¸ªä»»åŠ¡å¹¶è¡Œï¼‰
echo "æµ‹è¯• 2: 4 GPU å¹¶è¡Œ"
start=$(date +%s)
for gpu in 0 1 2 3; do
  for i in {1..10}; do
    curl -X POST http://localhost:8188/prompt \
      -H "Content-Type: application/json" \
      -H "X-TARGET-GPU: $gpu" \
      -d @test_workflow.json -s > /dev/null &
  done
done
wait
end=$(date +%s)
multi_time=$((end - start))
echo "4 GPU å¹¶è¡Œå®Œæˆ 40 ä¸ªä»»åŠ¡è€—æ—¶: ${multi_time}s"

# è®¡ç®—åŠ é€Ÿæ¯”
speedup=$(echo "scale=2; ($single_time * 4) / $multi_time" | bc)
echo "æ€§èƒ½æå‡: ${speedup}x"
EOF

chmod +x benchmark.sh
./benchmark.sh
```

**é¢„æœŸç»“æœ**ï¼š
```
æµ‹è¯• 1: å• GPU å®Œæˆ 10 ä¸ªä»»åŠ¡è€—æ—¶: 180s
æµ‹è¯• 2: 4 GPU å¹¶è¡Œå®Œæˆ 40 ä¸ªä»»åŠ¡è€—æ—¶: 200s
æ€§èƒ½æå‡: 3.60x
```

---

## ğŸŒ é˜¶æ®µ 4: é…ç½® Nginxï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

### æ­¥éª¤ 4.1: å®‰è£… Nginx

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install nginx

# CentOS/RHEL
sudo yum install nginx

# æ£€æŸ¥å®‰è£…
nginx -v
```

### æ­¥éª¤ 4.2: é…ç½® Nginx

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶
sudo cp nginx.conf /etc/nginx/sites-available/comfyui-multi-gpu

# åˆ›å»ºè½¯é“¾æ¥
sudo ln -s /etc/nginx/sites-available/comfyui-multi-gpu /etc/nginx/sites-enabled/

# æµ‹è¯•é…ç½®
sudo nginx -t
```

**é¢„æœŸè¾“å‡º**ï¼š
```
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
```

### æ­¥éª¤ 4.3: å¯åŠ¨ Nginx

```bash
# å¯åŠ¨ Nginx
sudo systemctl start nginx

# è®¾ç½®å¼€æœºè‡ªå¯
sudo systemctl enable nginx

# æ£€æŸ¥çŠ¶æ€
sudo systemctl status nginx
```

### æ­¥éª¤ 4.4: æµ‹è¯• Nginx ä»£ç†

```bash
# æµ‹è¯• 4 ä¸ªç«¯å£
for port in 8181 8182 8183 8184; do
  echo "Testing port $port..."
  curl -s http://localhost:$port/queue | jq .gpu_id
done
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Testing port 8181...
0
Testing port 8182...
1
Testing port 8183...
2
Testing port 8184...
3
```

### æ­¥éª¤ 4.5: é€šè¿‡ Nginx æäº¤ä»»åŠ¡

```bash
# æ¯ä¸ªç«¯å£è‡ªåŠ¨è·¯ç”±åˆ°å¯¹åº” GPU
curl -X POST http://localhost:8181/prompt -d @test_workflow.json  # â†’ GPU 0
curl -X POST http://localhost:8182/prompt -d @test_workflow.json  # â†’ GPU 1
curl -X POST http://localhost:8183/prompt -d @test_workflow.json  # â†’ GPU 2
curl -X POST http://localhost:8184/prompt -d @test_workflow.json  # â†’ GPU 3
```

---

## ğŸ“Š é˜¶æ®µ 5: éªŒè¯æ ¸å¿ƒç‰¹æ€§

### æµ‹è¯• 5.1: RAM å…±äº«éªŒè¯

```bash
# è®°å½• ComfyUI è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨
PID=$(pgrep -f "python main.py")
echo "ComfyUI PID: $PID"

# æäº¤ä»»åŠ¡å‰çš„å†…å­˜
RSS_BEFORE=$(ps -o rss= -p $PID)
echo "ä»»åŠ¡å‰ RSS: $((RSS_BEFORE / 1024))MB"

# å‘ 4 ä¸ª GPU æäº¤ç›¸åŒæ¨¡å‹çš„ä»»åŠ¡
for gpu in 0 1 2 3; do
  curl -X POST http://localhost:8188/prompt \
    -H "X-TARGET-GPU: $gpu" \
    -d @test_workflow.json -s > /dev/null &
done
wait

# ç­‰å¾…ä»»åŠ¡å®Œæˆ
sleep 30

# æäº¤ä»»åŠ¡åçš„å†…å­˜
RSS_AFTER=$(ps -o rss= -p $PID)
echo "ä»»åŠ¡å RSS: $((RSS_AFTER / 1024))MB"

# è®¡ç®—å¢é•¿
GROWTH=$((RSS_AFTER - RSS_BEFORE))
echo "å†…å­˜å¢é•¿: $((GROWTH / 1024))MB"
echo "å¢é•¿ç‡: $(echo "scale=2; ($GROWTH * 100) / $RSS_BEFORE" | bc)%"
```

**é¢„æœŸç»“æœ**ï¼š
- å†…å­˜å¢é•¿ < 10%ï¼ˆæ¨¡å‹åªåŠ è½½ä¸€æ¬¡ï¼‰
- å¦‚æœæ˜¯å¤šè¿›ç¨‹æ¨¡å¼ï¼Œå†…å­˜ä¼šå¢é•¿ 300%+

### æµ‹è¯• 5.2: æ¨¡å‹åŠ è½½é€Ÿåº¦

```bash
# åˆ›å»ºæ¨¡å‹åˆ‡æ¢æµ‹è¯•
cat > test_model_loading.sh << 'EOF'
#!/bin/bash

# ä¿®æ”¹ workflow ä½¿ç”¨ä¸åŒæ¨¡å‹
# æµ‹è¯•ä» RAM åŠ è½½çš„é€Ÿåº¦

echo "æµ‹è¯•æ¨¡å‹åŠ è½½é€Ÿåº¦..."

# æäº¤ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼ˆé¦–æ¬¡åŠ è½½ï¼Œä»ç¡¬ç›˜ï¼‰
echo "é¦–æ¬¡åŠ è½½ï¼ˆä»ç¡¬ç›˜åˆ° RAMï¼‰..."
time curl -X POST http://localhost:8188/prompt \
  -H "X-TARGET-GPU: 0" \
  -d @test_workflow.json -s > /dev/null

# ç­‰å¾…å®Œæˆ
sleep 20

# æäº¤ç¬¬äºŒä¸ªä»»åŠ¡åˆ°å¦ä¸€ä¸ª GPUï¼ˆä» RAM åŠ è½½ï¼‰
echo "å†æ¬¡åŠ è½½ï¼ˆä» RAM åˆ° VRAMï¼‰..."
time curl -X POST http://localhost:8188/prompt \
  -H "X-TARGET-GPU: 1" \
  -d @test_workflow.json -s > /dev/null
EOF

chmod +x test_model_loading.sh
./test_model_loading.sh
```

**é¢„æœŸç»“æœ**ï¼š
- é¦–æ¬¡åŠ è½½ï¼š5-10 ç§’
- åç»­åŠ è½½ï¼š1-2 ç§’ï¼ˆå¿« 3-5 å€ï¼‰

### æµ‹è¯• 5.3: é˜Ÿåˆ—éš”ç¦»

```bash
# å‘ GPU 0 æäº¤å¤§é‡ä»»åŠ¡
for i in {1..20}; do
  curl -X POST http://localhost:8181/prompt -d @test_workflow.json -s > /dev/null &
done

# ç«‹å³æŸ¥è¯¢æ‰€æœ‰é˜Ÿåˆ—
curl -s http://localhost:8188/queue/all | jq '.queues[] | {gpu: .gpu_id, pending: .pending_count}'
```

**é¢„æœŸè¾“å‡º**ï¼š
```json
{"gpu": 0, "pending": 20}
{"gpu": 1, "pending": 0}
{"gpu": 2, "pending": 0}
{"gpu": 3, "pending": 0}
```

**éªŒè¯**ï¼šåªæœ‰ GPU 0 çš„é˜Ÿåˆ—æœ‰ä»»åŠ¡ï¼Œå…¶ä»– GPU ä¸å—å½±å“ã€‚

### æµ‹è¯• 5.4: OOM æ¢å¤

```bash
# æäº¤ä¸€ä¸ªè¶…å¤§æ‰¹æ¬¡ä»»åŠ¡ï¼ˆæ•…æ„è§¦å‘ OOMï¼‰
cat > test_oom.json << 'EOF'
{
  "5": {
    "inputs": {
      "width": 4096,
      "height": 4096,
      "batch_size": 16
    },
    "class_type": "EmptyLatentImage"
  }
}
EOF

curl -X POST http://localhost:8188/prompt \
  -H "X-TARGET-GPU: 0" \
  -d @test_oom.json

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/comfyui_*.log | grep -E "(OOM|clearing cache)"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸ’¥ [GPU 0] OOM for prompt abc123, clearing cache
âœ… [GPU 0] Cache cleared, retrying...
```

---

## âœ… éªŒæ”¶æ ‡å‡†

### å¿…é¡»é€šè¿‡çš„æµ‹è¯•ï¼š

- [ ] **å¯åŠ¨æˆåŠŸ**ï¼šçœ‹åˆ° 4 ä¸ª worker å¯åŠ¨æ—¥å¿—
- [ ] **GPU è¯†åˆ«**ï¼š4 å¼  GPU éƒ½è¢«è¯†åˆ«å’Œé¢„çƒ­
- [ ] **ä»»åŠ¡è·¯ç”±**ï¼šä»»åŠ¡èƒ½æ­£ç¡®è·¯ç”±åˆ°æŒ‡å®š GPU
- [ ] **çœŸå¹¶è¡Œ**ï¼š4 å¼  GPU åŒæ—¶æ‰§è¡Œï¼ˆnvidia-smi éªŒè¯ï¼‰
- [ ] **é˜Ÿåˆ—éš”ç¦»**ï¼šå„ GPU é˜Ÿåˆ—ç‹¬ç«‹ï¼Œäº’ä¸å½±å“
- [ ] **RAM å…±äº«**ï¼šå†…å­˜å¢é•¿ < 10%
- [ ] **æ€§èƒ½æå‡**ï¼šååé‡è¾¾åˆ° 3.5x ä»¥ä¸Š

### æ€§èƒ½æŒ‡æ ‡ï¼š

```
å• GPU åŸºå‡†:
- å•å¼ å›¾ç‰‡ç”Ÿæˆ: 15-20 ç§’
- æ¯å°æ—¶ååé‡: 180-240 å¼ 

4 GPU å¹¶è¡Œï¼ˆç›®æ ‡ï¼‰:
- å•å¼ å›¾ç‰‡ç”Ÿæˆ: 15-20 ç§’ï¼ˆä¸å˜ï¼‰
- æ¯å°æ—¶ååé‡: 630-960 å¼ ï¼ˆ3.5-4xï¼‰
- RAM å¢é•¿: < 10%
- æ¨¡å‹åŠ è½½åŠ é€Ÿ: 3-5x
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: å¯åŠ¨æ—¶åªçœ‹åˆ°å• GPU æ—¥å¿—

**æ£€æŸ¥**ï¼š
```bash
echo $COMFY_MULTI_GPU_SCHED
echo $COMFY_NUM_GPUS
```

**è§£å†³**ï¼š
```bash
export COMFY_MULTI_GPU_SCHED=1
export COMFY_NUM_GPUS=4
```

### é—®é¢˜ 2: æ‰€æœ‰ä»»åŠ¡éƒ½åœ¨ GPU 0

**æ£€æŸ¥ Nginx**ï¼š
```bash
sudo nginx -T | grep X-TARGET-GPU
```

**åº”è¯¥çœ‹åˆ°**ï¼š
```
proxy_set_header X-TARGET-GPU 0;
proxy_set_header X-TARGET-GPU 1;
...
```

### é—®é¢˜ 3: GPU 1/2/3 æ²¡æœ‰è´Ÿè½½

**æŸ¥çœ‹æ—¥å¿—**ï¼š
```bash
grep "Worker started" logs/comfyui_*.log
```

**åº”è¯¥çœ‹åˆ°**ï¼š
```
ğŸ”§ [GPU 0] Worker started on cuda:0
ğŸ”§ [GPU 1] Worker started on cuda:1
ğŸ”§ [GPU 2] Worker started on cuda:2
ğŸ”§ [GPU 3] Worker started on cuda:3
```

**å¦‚æœç¼ºå¤±**ï¼Œæ£€æŸ¥ï¼š
```bash
python -c "import torch; print(torch.cuda.device_count())"
# å¿…é¡»è¿”å› 4
```

### é—®é¢˜ 4: OOM å´©æºƒ

**å¢åŠ é”™è¯¯æ¢å¤**ï¼š
- æ£€æŸ¥æ—¥å¿—ä¸­çš„ OOM è®¡æ•°
- å¦‚æœé¢‘ç¹ OOMï¼Œå‡å° batch size
- æˆ–è€…ä½¿ç”¨æ›´å°çš„æ¨¡å‹

### é—®é¢˜ 5: æ€§èƒ½æ²¡æœ‰æå‡

**å¯èƒ½åŸå› **ï¼š
1. æ¨¡å‹å¤ªå°ï¼ŒGPU æœªå……åˆ†åˆ©ç”¨
2. ç¡¬ç›˜ I/O ç“¶é¢ˆï¼ˆä½¿ç”¨ NVMe SSDï¼‰
3. CPU ç“¶é¢ˆï¼ˆå¢åŠ  CPU æ ¸å¿ƒï¼‰

**æµ‹è¯•**ï¼š
```bash
# ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ‰¹æ¬¡
# ç¡®ä¿ GPU åˆ©ç”¨ç‡ > 80%
```

---

## ğŸ“ æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿

å®Œæˆæµ‹è¯•åï¼Œå¡«å†™ä»¥ä¸‹æŠ¥å‘Šï¼š

```markdown
# ComfyUI å¤š GPU æµ‹è¯•æŠ¥å‘Š

## ç¯å¢ƒä¿¡æ¯
- GPU å‹å·: _______
- GPU æ•°é‡: 4
- VRAM: _______/å¡
- RAM: _______
- CUDA ç‰ˆæœ¬: _______
- ComfyUI ç‰ˆæœ¬: v0.3.68

## æµ‹è¯•ç»“æœ

### åŸºç¡€åŠŸèƒ½
- [ ] å¯åŠ¨æˆåŠŸ
- [ ] 4 GPU è¯†åˆ«
- [ ] ä»»åŠ¡è·¯ç”±æ­£å¸¸
- [ ] é˜Ÿåˆ—éš”ç¦»æ­£å¸¸

### æ€§èƒ½æµ‹è¯•
- å• GPU ååé‡: _______ å¼ /å°æ—¶
- 4 GPU ååé‡: _______ å¼ /å°æ—¶
- åŠ é€Ÿæ¯”: _______x
- RAM å¢é•¿ç‡: _______%
- æ¨¡å‹åŠ è½½åŠ é€Ÿ: _______x

### ç¨³å®šæ€§
- è¿ç»­è¿è¡Œæ—¶é—´: _______ å°æ—¶
- OOM æ¬¡æ•°: _______
- ä»»åŠ¡æˆåŠŸç‡: _______%

### é—®é¢˜è®°å½•
ï¼ˆå¦‚æœ‰é—®é¢˜ï¼Œè¯¦ç»†æè¿°ï¼‰

### ç»“è®º
â–¡ é€šè¿‡æµ‹è¯•ï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨
â–¡ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–
â–¡ å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ä¿®å¤
```

---

## ğŸ‰ æµ‹è¯•æˆåŠŸå

### ç”Ÿäº§éƒ¨ç½²æ¸…å•ï¼š

- [ ] é…ç½® systemd æœåŠ¡ï¼ˆå¼€æœºè‡ªå¯ï¼‰
- [ ] é…ç½®æ—¥å¿—è½®è½¬
- [ ] è®¾ç½®ç›‘æ§å‘Šè­¦
- [ ] é…ç½®é˜²ç«å¢™è§„åˆ™
- [ ] æ–‡æ¡£åŒ–éƒ¨ç½²æµç¨‹
- [ ] åŸ¹è®­è¿ç»´å›¢é˜Ÿ

### systemd æœåŠ¡é…ç½®ï¼š

```bash
sudo nano /etc/systemd/system/comfyui-multi-gpu.service
```

```ini
[Unit]
Description=ComfyUI Multi-GPU Service
After=network.target

[Service]
Type=simple
User=ä½ çš„ç”¨æˆ·å
WorkingDirectory=/path/to/ComfyUI
Environment="CUDA_VISIBLE_DEVICES=0,1,2,3"
Environment="COMFY_MULTI_GPU_SCHED=1"
Environment="COMFY_NUM_GPUS=4"
ExecStart=/usr/bin/python3 main.py --listen 0.0.0.0 --port 8188
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable comfyui-multi-gpu
sudo systemctl start comfyui-multi-gpu
```

---

ç¥æµ‹è¯•é¡ºåˆ©ï¼ğŸš€
